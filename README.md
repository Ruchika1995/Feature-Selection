# Feature-Selection
The goal of feature selection in machine learning is to find the best set of features that allows one to build useful models of studied phenomena.

The techniques for feature selection in machine learning can be broadly classified into the following categories:

Supervised Techniques: These techniques can be used for labeled data, and are used to identify the relevant features for increasing the efficiency of supervised models like classification and regression.

Unsupervised Techniques: These techniques can be used for unlabeled data.

From a taxonomic point of view, these techniques are classified as under:

A. Filter methods - 
  1. Information Gain
  2. Chi-Square Test
  3. Fisher's Score
  4. Correlation Coefficient
  5. Varince Threshold
  6. Mean Absolute Difference(MAD)
  7. Dispersion Ratio

B. Wrapper methods - 
  1. Forward Feature Selection
  2. Backward Feature Selection
  3. Exhaustive Feature Selection
  4. Recursive Feature Elimination

C. Embedded methods -
  1. Lasso Regularization(L1)
  2. Random Forest Importance

D. Hybrid methods
